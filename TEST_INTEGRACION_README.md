# Tests de IntegraciÃ³n del Sistema VarP

## ðŸ“‹ Resumen

Los tests de integraciÃ³n verifican el funcionamiento correcto del sistema completo end-to-end, incluyendo:

- âœ… **Test 1**: Procesamiento de **10,000 escenarios**
- âœ… **Test 2**: **5 consumidores paralelos** con fair dispatch
- âœ… **Test 3**: **RecuperaciÃ³n ante fallo** de consumidor
- âœ… **Test 4**: **Cambio de modelo** con purga correcta

Estos tests validan que el sistema funciona correctamente en escenarios reales de producciÃ³n.

## âš ï¸ Pre-requisitos

### 1. RabbitMQ Corriendo

Los tests de integraciÃ³n **REQUIEREN** RabbitMQ ejecutÃ¡ndose en `localhost:5672`:

```bash
# OpciÃ³n 1: Docker (recomendado)
docker run -d --name rabbitmq \
  -p 5672:5672 \
  -p 15672:15672 \
  -e RABBITMQ_DEFAULT_USER=admin \
  -e RABBITMQ_DEFAULT_PASS=password \
  rabbitmq:3-management

# OpciÃ³n 2: Sistema local
# (Asegurarse que RabbitMQ estÃ¡ instalado y corriendo)
sudo systemctl start rabbitmq-server

# Verificar que estÃ¡ corriendo
curl -u admin:password http://localhost:15672/api/overview
```

### 2. Dependencias Instaladas

```bash
pip install -r requirements.txt
```

### 3. Modelos de Ejemplo

Los tests usan modelos de la carpeta `modelos/`:
- `ejemplo_simple.ini`
- `ejemplo_6_dist_simple.ini`

Estos modelos ya deben estar presentes en el repositorio.

## ðŸ§ª Ejecutar Tests

### Ejecutar Todos los Tests

```bash
python test_integracion.py
```

**Output esperado:**
```
test_1_escenarios_10000 ... ok
test_2_cinco_consumidores_paralelos ... ok
test_3_recuperacion_fallo_consumidor ... ok
test_4_cambio_modelo_purga ... ok
test_throughput_productor ... ok

----------------------------------------------------------------------
Ran 5 tests in 180.234s

OK
```

### Ejecutar Test EspecÃ­fico

```bash
# Solo test de 10,000 escenarios
python test_integracion.py TestIntegracionSistemaCompleto.test_1_escenarios_10000

# Solo test de 5 consumidores paralelos
python test_integracion.py TestIntegracionSistemaCompleto.test_2_cinco_consumidores_paralelos

# Solo test de recuperaciÃ³n ante fallo
python test_integracion.py TestIntegracionSistemaCompleto.test_3_recuperacion_fallo_consumidor

# Solo test de cambio de modelo
python test_integracion.py TestIntegracionSistemaCompleto.test_4_cambio_modelo_purga
```

### Ejecutar con Verbose

```bash
python test_integracion.py -v
```

## ðŸ“Š DescripciÃ³n de Tests

### Test 1: 10,000 Escenarios

**Objetivo**: Verificar que el sistema puede procesar un volumen grande de escenarios.

**Pasos:**
1. Productor genera 10,000 escenarios usando `ejemplo_simple.ini`
2. 1 consumidor procesa todos los escenarios
3. Se verifica que todos los resultados se publican

**MÃ©tricas verificadas:**
- âœ… 10,000 escenarios generados
- âœ… 10,000 escenarios en cola
- âœ… â‰¥99% de resultados procesados
- âœ… Throughput > 100 esc/s (productor + consumidor)

**Tiempo estimado**: ~1-3 minutos

### Test 2: 5 Consumidores Paralelos

**Objetivo**: Verificar distribuciÃ³n equitativa de carga con mÃºltiples consumidores.

**Pasos:**
1. Productor genera 5,000 escenarios
2. **5 consumidores** se lanzan en procesos separados
3. Todos procesan concurrentemente usando prefetch_count=1 (fair dispatch)
4. Se verifica distribuciÃ³n y throughput

**MÃ©tricas verificadas:**
- âœ… 5,000 escenarios generados
- âœ… â‰¥95% de escenarios procesados
- âœ… Fair dispatch funciona (sin starvation)
- âœ… Throughput aumenta con mÃ¡s consumidores
- âœ… EstadÃ­sticas de todos los consumidores publicadas

**Tiempo estimado**: ~1-2 minutos

### Test 3: RecuperaciÃ³n ante Fallo

**Objetivo**: Verificar que el sistema es resiliente ante fallos de consumidores.

**Pasos:**
1. Productor genera 1,000 escenarios
2. Consumidor 1 procesa ~5 escenarios y luego **FALLA**
3. Consumidor 2 (backup) se lanza y procesa los escenarios restantes
4. Se verifica que todos los escenarios se procesaron

**MÃ©tricas verificadas:**
- âœ… 1,000 escenarios generados
- âœ… Consumidor 1 procesa <50% antes de fallar
- âœ… >50% de escenarios quedan en cola despuÃ©s del fallo
- âœ… Consumidor 2 procesa los restantes
- âœ… â‰¥95% de escenarios procesados al final
- âœ… **Sin pÃ©rdida de mensajes**

**Tiempo estimado**: ~30-60 segundos

**ValidaciÃ³n clave**: Demuestra que el sistema NO pierde mensajes cuando un consumidor falla, gracias al ACK manual de RabbitMQ.

### Test 4: Cambio de Modelo con Purga

**Objetivo**: Verificar que se puede cambiar el modelo correctamente.

**Pasos:**
1. Productor 1 publica `ejemplo_simple.ini` + 100 escenarios
2. Verificar que hay 1 modelo y 100 escenarios en colas
3. Productor 2 publica `ejemplo_6_dist_simple.ini` + 200 escenarios
4. **Verificar purga**: modelo antiguo debe ser reemplazado
5. Purgar escenarios antiguos manualmente
6. Generar escenarios con nuevo modelo
7. Consumidor procesa con nuevo modelo

**MÃ©tricas verificadas:**
- âœ… Modelo antiguo se purga automÃ¡ticamente
- âœ… Solo 1 modelo en cola (el nuevo)
- âœ… Modelo cambiÃ³ correctamente (verificado por modelo_id)
- âœ… Escenarios antiguos se pueden purgar manualmente
- âœ… Consumidor carga y usa nuevo modelo
- âœ… â‰¥90% de escenarios procesados con nuevo modelo

**Tiempo estimado**: ~1 minuto

**Nota importante**: La cola de modelo se purga automÃ¡ticamente en `producer._publicar_modelo()`, pero los escenarios antiguos deben purgarse manualmente si se desea. Esto es intencional para prevenir pÃ©rdida accidental de datos.

### Test 5: Throughput del Productor

**Objetivo**: Medir performance del productor.

**Pasos:**
1. Productor genera 5,000 escenarios
2. Se mide tiempo total
3. Se calcula throughput

**MÃ©tricas verificadas:**
- âœ… Throughput > 100 esc/s

**Tiempo estimado**: ~30 segundos

## ðŸŽ¯ Criterios de Ã‰xito

Para que los tests pasen, se deben cumplir:

### Funcionalidad
- âœ… Todos los escenarios se generan correctamente
- âœ… Todos los escenarios se procesan (â‰¥95% o â‰¥99% segÃºn test)
- âœ… No hay pÃ©rdida de mensajes ante fallos
- âœ… Cambio de modelo funciona correctamente

### Performance
- âœ… Throughput productor > 100 esc/s
- âœ… Sistema completo procesa 10,000 escenarios en < 5 minutos
- âœ… MÃºltiples consumidores mejoran throughput

### Resiliencia
- âœ… Sistema se recupera de fallos de consumidor
- âœ… Mensajes no se pierden (ACK manual)
- âœ… Fair dispatch distribuye carga equitativamente

## ðŸ› Troubleshooting

### Error: "RabbitMQ no disponible"

**Causa**: RabbitMQ no estÃ¡ corriendo o no estÃ¡ en `localhost:5672`.

**SoluciÃ³n**:
```bash
# Verificar que RabbitMQ estÃ¡ corriendo
docker ps | grep rabbitmq

# Si no estÃ¡, iniciarlo
docker run -d --name rabbitmq \
  -p 5672:5672 -p 15672:15672 \
  -e RABBITMQ_DEFAULT_USER=admin \
  -e RABBITMQ_DEFAULT_PASS=password \
  rabbitmq:3-management

# Esperar 10 segundos a que inicie
sleep 10
```

### Tests se Saltan (SKIPPED)

Si ves:
```
test_1_escenarios_10000 (test_integracion.TestIntegracionSistemaCompleto) ... skipped 'RabbitMQ no disponible'
```

**Causa**: RabbitMQ no estÃ¡ accesible.

**SoluciÃ³n**: Ver secciÃ³n anterior.

### Test Timeout

Si un test se queda esperando mucho tiempo:

**Causas posibles**:
1. RabbitMQ muy lento (falta de recursos)
2. Consumidores no procesan (error en cÃ³digo)
3. Colas llenas (aumentar lÃ­mites)

**SoluciÃ³n**:
```bash
# Ver logs de RabbitMQ
docker logs rabbitmq

# Ver estado de colas
# (Usar management UI: http://localhost:15672)
# Usuario: admin, Password: password

# Purgar colas manualmente si es necesario
python -c "
from src.common.rabbitmq_client import RabbitMQClient
from src.common.config import QueueConfig
client = RabbitMQClient()
client.connect()
client.declare_queues()
for q in [QueueConfig.ESCENARIOS, QueueConfig.RESULTADOS]:
    client.purge_queue(q)
"
```

### Procesos Zombie

Si despuÃ©s de tests quedan procesos zombie:

```bash
# Ver procesos Python
ps aux | grep python

# Matar procesos si es necesario
pkill -9 -f "run_consumer_process"
```

### Throughput Bajo

Si el throughput es muy bajo (< 10 esc/s):

**Causas**:
- RabbitMQ en Docker con pocos recursos
- MÃ¡quina muy lenta
- Modelo complejo

**SoluciÃ³n**:
- Aumentar recursos de Docker
- Usar modelo mÃ¡s simple
- Los tests ajustan automÃ¡ticamente los umbrales

## ðŸ“ˆ InterpretaciÃ³n de Resultados

### Ejemplo de Output Exitoso

```
==============================================================
TEST 1: 10,000 ESCENARIOS
==============================================================
âœ“ Productor generÃ³ 10000 escenarios en 45.23s
  Tasa: 221.05 esc/s
âœ“ Cola de escenarios tiene 10000 mensajes
  Progreso: 10000/10000 resultados
âœ“ Consumidor procesÃ³ 10000 escenarios en 52.34s
  Tasa: 191.06 esc/s
âœ“ Throughput total: 102.47 esc/s
==============================================================
TEST 1: EXITOSO âœ“
==============================================================
```

**InterpretaciÃ³n:**
- Productor generÃ³ 10K escenarios a 221 esc/s
- Consumidor procesÃ³ 10K escenarios a 191 esc/s
- Throughput total del sistema: 102 esc/s
- **TODO OK** âœ“

### Throughput Esperado

Depende del hardware, pero valores tÃ­picos:

| Componente | Throughput Esperado |
|------------|---------------------|
| Productor solo | 200-500 esc/s |
| Consumidor solo | 100-300 esc/s |
| Sistema completo (1 cons) | 80-150 esc/s |
| Sistema completo (5 cons) | 200-500 esc/s |

**Nota**: Con modelos complejos (cÃ³digo Python), el throughput serÃ¡ menor.

## ðŸ”§ ConfiguraciÃ³n

Los tests usan la configuraciÃ³n por defecto de `src/common/config.py`:

```python
# RabbitMQ
RABBITMQ_HOST = 'localhost'
RABBITMQ_PORT = 5672
RABBITMQ_USER = 'admin'
RABBITMQ_PASS = 'password'

# Prefetch (Fair Dispatch)
CONSUMER_PREFETCH_COUNT = 1

# Connection Pooling
POOL_SIZE = 10
POOL_MAX_OVERFLOW = 5
```

Para modificar, usar variables de entorno:

```bash
export RABBITMQ_HOST=my-rabbit-server
export RABBITMQ_PORT=5672
python test_integracion.py
```

## ðŸ“ Notas Importantes

### Multiprocessing

Los tests usan `multiprocessing` para lanzar consumidores en procesos separados (no threads), simulando el comportamiento real donde cada consumidor es un proceso independiente.

**Inicio del mÃ©todo**:
```python
multiprocessing.set_start_method('spawn', force=True)
```

Esto garantiza compatibilidad cross-platform (Linux, macOS, Windows).

### Limpieza de Colas

Cada test purga todas las colas antes de ejecutarse (`setUp()`), garantizando:
- âœ… Tests independientes
- âœ… No interferencia entre tests
- âœ… Estado limpio

### Timeouts

Los tests tienen timeouts configurados:
- Test 1 (10K): 300s (5 minutos)
- Test 2 (5 cons): 120s (2 minutos)
- Test 3 (fallo): 60s (1 minuto)
- Test 4 (cambio): 60s (1 minuto)

Si un test excede el timeout, **falla**.

### Logging

Los tests usan nivel `WARNING` por defecto para reducir ruido:

```python
logging.basicConfig(level=logging.WARNING)
```

Para ver mÃ¡s detalles, cambiar a `INFO` o `DEBUG`:

```python
logging.basicConfig(level=logging.INFO)
```

## ðŸŽ“ Uso Avanzado

### Ejecutar con Coverage

```bash
pip install pytest-cov
pytest test_integracion.py --cov=src --cov-report=html
```

### Ejecutar N veces

```bash
# Ejecutar 10 veces para detectar race conditions
for i in {1..10}; do
    echo "=== Run $i ==="
    python test_integracion.py || break
done
```

### Ejecutar en Paralelo (NO recomendado)

Los tests de integraciÃ³n NO deben ejecutarse en paralelo porque comparten la misma instancia de RabbitMQ y colas.

### Stress Testing

Para stress testing mÃ¡s intenso:

```python
# Modificar test_1_escenarios_10000
num_escenarios = 100000  # 100K escenarios
```

## ðŸ“š Referencias

- **RabbitMQ Docs**: https://www.rabbitmq.com/documentation.html
- **Pika (Python Client)**: https://pika.readthedocs.io/
- **Fair Dispatch**: https://www.rabbitmq.com/tutorials/tutorial-two-python.html
- **Message Acknowledgment**: https://www.rabbitmq.com/confirms.html

---

**Tests de IntegraciÃ³n** - Sistema VarP Monte Carlo
Validan funcionamiento completo end-to-end con escenarios reales de producciÃ³n.
